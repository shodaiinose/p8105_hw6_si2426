---
title: "p8105_hw6_si2426"
output: github_document
author: "Shodai Inose"
date: "2022-12-2"
---

```{r, include = FALSE}
library(tidyverse)
library(purrr)
library(epiDisplay)
library(glmnet)
library(modelr)
library(mgcv)
```

## Problem 2

#### Loading and Cleaning Data

```{r, warning = FALSE}
homicide_df = read.csv("./data/homicide-data.csv") %>% 
  mutate(city_state = paste(city, state, sep = ", "), 
         solved = ifelse(disposition == "Closed by arrest", 1, 0), victim_age = as.numeric(victim_age), victim_race = fct_relevel(victim_race, "White")) %>%
  filter(city_state != "Dallas, TX", city_state != "Phoenix, AZ",
           city_state != "Kansas City, MO",
           city_state != "Tulsa, AL") %>%
  filter(victim_race ==  "White" | victim_race ==  "Black")
```

The data was wrangled and cleaned by creating a variable for `city_state` and a binary variable `solved` to identify cases that were closed by an arrest. Several cities were filtered out and only victims who are categorized as White or Black will be analyzed. 

#### Baltimore, MD Logistic Regression
```{r}
baltimore_homicide = homicide_df %>% 
  filter(city == "Baltimore")

baltimore_logistic = 
  baltimore_homicide %>% 
  glm(solved ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) 

baltimore_logistic_df = 
  baltimore_logistic %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate)) 

baltimore_logistic_table = baltimore_logistic_df %>%
  dplyr::select(term, log_OR = estimate, OR, p.value) %>% 
  knitr::kable(digits = 3)

baltimore_logistic_table
```

The estimated odds ratio for solving homicides in Baltimore, MD with a male victim, keeping all other variables fixed, is 0.426.

```{r}
as_tibble(confint(baltimore_logistic)) %>% slice(4) %>% exp()
```

A 95% confidence interval for the adjusted odds ratio for solving homicides in Baltimore, Maryland in which the victim is male (keeping all other variables fixed) is (0.32, 0.56). Since this interval does not contain the value of 1, this indicates that homicides in which the victim is male are less likely to be solved than cases in which the victim is female in Baltimore, Maryland.

#### All Cities
```{r, message = FALSE}
cities_logistic = homicide_df %>% 
  group_by(city_state) %>% 
  nest() %>%
  mutate( 
    models = map(data, ~glm(data = .x, solved ~ victim_age + victim_race + victim_sex, family = binomial())),
    result = map(models, broom::tidy)) %>%
  dplyr:: select(-data, -models)  %>% 
  unnest(result) %>%
  mutate(OR = exp(estimate)) %>%
  dplyr:: select(term, log_OR = estimate, std_error = std.error, OR, p.value) %>%
  mutate(lwr = exp(log_OR - 1.96*std_error), upr = exp(log_OR + 1.96*std_error))

cities_logistic =
  cities_logistic[, c("city_state", "term", "log_OR", "std_error", "OR", 
                      "lwr", "upr",
                      "p.value")]
```

```{r}
victim_sex_logistic = cities_logistic %>% 
  filter(term == "victim_sexMale") %>%
  ungroup(city_state) %>%
  mutate(city_state = fct_reorder(city_state, OR))

ggplot(victim_sex_logistic, aes(x = city_state, y = OR)) + 
  geom_point() +
  geom_errorbar(aes(ymin = lwr, ymax = upr)) +
  labs(x = "City, State", y = "Adjusted Odds Ratio") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

According to the plot, Albuquerque, NM has the highest estimated odds ratio while New York, NY has the lowest estimated odds ratio. In a majority of cities, the confidence interval of the odds ratio is between 0 and 1, indicating that in many cities, homicides in which the victim is male are less likely to be solved than those with female victims (keeping all other variables constant). It can be noted that cities with higher estimated odds ratios tend to have wider confidence intervals, such as Albuquerque, NM.

## Problem 3

#### Loading and Cleaning Data
```{r}
birthweight_df = read.csv("./data/birthweight.csv") %>%
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace))
```

The data was cleaned by converting numeric variables such as `babysex`, `frace`, `malform`, and `mrace` to factor variables. 

```{r}
sum(is.na(birthweight_df))
```
There are no missing values in the data.

#### Fitting a Model

In order to study the relationship between birthweight and several factors, we will fit a model with all variables and perform a stepwise regression to find an appropriate model.

```{r}
full_model = lm(bwt ~., birthweight_df)

step_model =  stepAIC(full_model, direction = "both", 
                      trace = FALSE)

step_model %>% 
  broom::tidy() %>% 
  dplyr::select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

Running the stepwise regression, we will be studying the relationship between birthweight and the following independent variables: babysex, baby's head circumference, baby's length, mother's weight at delivery, family income, gestational age, mother's height, number of live births prior to this pregnancy, mother's pre-pregnancy weight, and average number of cigarettes smoked per day.

#### Plotting Residuals
```{r}
birthweight_df %>% 
  add_residuals(step_model) %>% 
  add_predictions(step_model) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  ggtitle("Residuals vs. Fitted Values") +
  xlab("Fitted Values") + ylab("Residuals")
```

Looking at the residuals vs. fitted values plot, it appears that for higher values of birthweight, the residuals are evenly distributed around 0. However, for lower values of birthweight, the residuals tend to be distributed greater than 0, indicating possible skew in the data.

#### Comparing Models

In order to find the model that best predicts birthweight, we will use cross validation to compare the stepwise model with two other models. One model will look at length at birth and gestational age (main effects) while the other model will look at head circumference, length, sex, and all interactions.

```{r, warning = FALSE}
set.seed(8167)
comparing_models =
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

comparing_models = 
  comparing_models %>% 
  mutate(
    step.model  = map(train, ~lm(bwt ~ 
      babysex + bhead + blength + delwt + fincome + 
      gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
    main_effects = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    interaction = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x))) %>%
  mutate(
    rmse_step = map2_dbl(step.model, test, ~rmse(model = .x, data = .y)),
    rmse_main   = map2_dbl(main_effects, test, ~rmse(model = .x, data = .y)),
    rmse_interaction = map2_dbl(interaction, test, ~rmse(model = .x, data = .y)))

comparing_models %>% 
  dplyr::select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

According to the cross validation, it is apparent that the step-wise model has the lowest RMSE value while the main effects model has the highest RMSE. This means that it may be most appropriate to fit the step-wise model to predict birthweight. 


